{
    "collab_server" : "",
    "contents" : "\n---\ntitle: \"Of dags and clues\"\nauthor: \"Macartan Humphreys and Alan Jacobs\"\ndate: \"November 4, 2016\"\noutput: \n  beamer_presentation:\nlevels: 2\n---\n\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(echo = FALSE)\n\nhj_dag <- function(x, \n                   y, \n                   names, \n                   arcs = cbind(0,0), \n                   add_points = FALSE,\n                   solids = rep(1, length(x)), \n                   title = \"\", \n                   contraction = .1, \n                   add_functions = 0, \n                   add_functions_text = NULL, \n                   text_shift = .2*add_points) {\nif(add_points)  plot(x, y, pch=ifelse(solids == 1, 19, 1), cex = 2, axes = FALSE, xlab = \"\", ylab = \"\", \n       xlim = c(min(x)-1, max(x)+1),\n       ylim = c(min(y)-1-add_functions, max(y)+1),\n       main = title)\nif(!add_points)  plot(x, y, type = \"n\", cex = 2, axes = FALSE, xlab = \"\", ylab = \"\", \n       xlim = c(min(x)-1, max(x)+1),\n       ylim = c(min(y)-1-add_functions, max(y)+1),\n       main = title)\n\n    arrows(x[arcs[,1]]*(1-contraction) + x[arcs[,2]]*contraction, \n         y[arcs[,1]]*(1-contraction) + y[arcs[,2]]*contraction, \n         x[arcs[,2]]*(1-contraction) + x[arcs[,1]]*contraction,\n         y[arcs[,2]]*(1-contraction) + y[arcs[,1]]*contraction)\n  text(x, y + text_shift, names)\n  if(!is.null(add_functions_text)) text(((min(x)+max(x))/2), min(y)-1, add_functions_text)\n  box()\n}\n```\n\n\n# Introduction\n\n## Motivation\n\nWhat is process tracing, and what is it good for?\n\n* A strategy of within-case empirical inquiry into causal relations\n\n* Challenges of cross-case inference\n\n    + Confounding in absence of (as if) random assignment\n    \n    + Focus on whether $X$ causes $Y$, less on how\n    \n* Process tracing is supposed to offer $X \\rightarrow Y$ causal inferences at case level, without random assignment, plus information about mechanisms through which $X$ affects $Y$\n\n\n## Motivation\n\nBut how does process tracing do this?\n\nStandard accounts:\n\n* Tracing a whole causal chain from $X$ to $Y$\n\n    + How is this different from description? Storytelling?\n\n* Go looking for things we should see if $X$ caused $Y$\n\n    + But what are those?\n    \n    + Come from theory -- but how?\n\n* Test types (smoking gun, hoop, etc) or more probabilistic, Bayesian versions\n\n    + Good for conceptualizing probative value\n    \n    + But begs the question of where that probative value comes from\n    \n    + Why is a piece of case evidence associated with a causal effect or mechanism?\n\n* **What gives within-case data probative value?**\n\n    \n\n\n\n\n# From Theory to DAGs\n## What is a theory?\n\n* Suppose I claim that X causes Y\n    + Specifically, $Y=X$\n\n\n```{r, echo = FALSE, fig.width = 3, fig.height = 3, fig.align='right'}\n\nhj_dag(x = c(1, 2, 2),\n       y = c(1, 1, 2),\n       names = c(\"X\",\"Y\", \"U_y\"),\n       arcs = cbind( c(1, 3),\n                     c(2, 2)),\n       add_functions = 0, \n       contraction = .2\n       )\n\n```\n\n\n* You ask me what my __theory__ is\n\n* How should I respond?\n\n* __With a lower-level DAG.__\n\n\n## DAGs in levels \n\n* Define the \"level\" of a DAG as being its degree of detail\n\n* DAGs are nested in levels\n\n    + Every DAG is a simplification of a more detailed, lower-level DAG\n    \n    + A lower-level DAG includes all nodes and edges of a higher-level DAG that it implies\n    \n* But not a 1-to-1 mapping\n\n    + A given DAG can _imply_ multiple higher-level (simpler) DAGs\n    + A given DAG can be _implied by_ multiple lower-level DAGs (possibly compatible or incompatible with each other)\n\n* A lower-level DAG is a __theory__ of a higher-level DAG that it implies\n\n## Lower-level DAGs: Additional Causes\n\n* Lower-level DAG may incorporate causes not shown in higher-level DAG\n\n```{r, echo = FALSE, fig.width = 3, fig.height = 3, fig.align='center'}\n\nhj_dag(x = c(1, 1, 2, 2),\n       y = c(1, 2, 1, 2),\n       names = c(\"X\",\"C\", \"Y\", \"U_y\"),\n       arcs = cbind( c(1, 4, 2),\n                     c(3, 3, 3)),\n       add_functions = 0, \n       contraction = .2\n       )\n\n```\n\n* May be additive, e.g., $Y=X+C$\n\n* May be interactive, e.g., $Y=XC$\n\n\n## Lower-level DAGs: Interactive Causes\n\n* A higher-level DAG is a _projection_ of a lower level DAG\n    + For some settings on nodes\n\n* Take special case of interaction: $Y=XC$\n\n* Then, this...\n\n```{r, echo = FALSE, fig.width = 2.5, fig.height = 2.5, fig.align='center'}\n\nhj_dag(x = c(1, 2, 2),\n       y = c(1, 1, 2),\n       names = c(\"X\",\"Y\", \"U_y\"),\n       arcs = cbind( c(1, 3),\n                     c(2, 2)),\n       add_functions = 0, \n       contraction = .2\n       )\n\n```\n\n    is a special case of this...\n\n```{r, echo = FALSE, fig.width = 2.5, fig.height = 2.5, fig.align='center'}\n\nhj_dag(x = c(1, 1, 2, 2),\n       y = c(1, 2, 1, 2),\n       names = c(\"X\",\"C\", \"Y\", \"U_y\"),\n       arcs = cbind( c(1, 4, 2),\n                     c(3, 3, 3)),\n       add_functions = 0, \n       contraction = .2\n       )\n\n```\n\n    ...when C=1.\n\n\n## Lower-level DAGs: Unpacking $U_y$\n\n* The lower-level DAG also removes variance from $U_y$\n\n* Take special case of interaction: $Y=XC$\n\n* Here $U_y$ includes everything other than $X$ that affects $Y$\n\n```{r, echo = FALSE, fig.width = 2.5, fig.height = 2.5, fig.align='center'}\n\nhj_dag(x = c(1, 2, 2),\n       y = c(1, 1, 2),\n       names = c(\"X\",\"Y\", \"U_y\"),\n       arcs = cbind( c(1, 3),\n                     c(2, 2)),\n       add_functions = 0, \n       contraction = .2\n       )\n\n```\n\n* But here $C$ has been pulled out of $U_y$, reducing $U_y$'s variance (__IS THAT RIGHT?__)\n\n```{r, echo = FALSE, fig.width = 2.5, fig.height = 2.5, fig.align='center'}\n\nhj_dag(x = c(1, 1, 2, 2),\n       y = c(1, 2, 1, 2),\n       names = c(\"X\",\"C\", \"Y\", \"U_y\"),\n       arcs = cbind( c(1, 4, 2),\n                     c(3, 3, 3)),\n       add_functions = 0, \n       contraction = .2\n       )\n\n```\n\n\n    \n## Lower-level DAGs: Mediation\n\n* Lower-level DAGs may spell out steps in causal chain not incorporated in simpler DAG\n\n```{r, echo = FALSE, fig.width = 3, fig.height = 3}\n\nhj_dag(x = c(1, 2, 2, 3, 3),\n       y = c(1, 1, 2, 1, 2),\n       names = c(\"X\",\"M\", \"u_m\", \"Y\", \"U_y\"),\n       arcs = cbind( c(1, 2, 3, 5),\n                     c(2, 4, 2, 4)),\n             add_functions = 0, \n       contraction = .2\n       )\n\n```\n\n* Makes explicit a second step at which $X$->$Y$ effect could break down\n\n    + If $U_{m}$ takes on a value that fixes $M$ or constrains $M$'s response to $X$\n    \n## Lower-level DAGs: Mediation\n\nTwo interpretations of the higher-level DAG:\n\n* The term $u_y$ is a _composite_ of exogenous influences on $M$ and exogenous influences on $Y$\n    \n    + Higher-level graph still covers full parameter space\n    \nOR\n  \n* The higher-level DAG is implied by the lower-level DAG for a given value (or range of values) of $U_m$\n    \n    + Higher-level graph is a projection of lower-level graph\n    \n    + $Y=X$ | $U_m$ = $u^*_{m}$\n\n\n\n    \n## From DAGs to Clues: Simple DAG\n\n* Imagine a single case in which there is a free press and a government is replaced\n\n* Start with a simple, case-level question about causes: did the free press cause the government to be replaced?\n\n* The associated DAG\n\n```{r, echo = FALSE, fig.width = 3, fig.height = 3}\n\n  hj_dag(x = c(1, 2, 2),\n         y = c(1, 1, 2),\n         names = c(\"Free Press\", \"Govt replaced\", expression(paste(U[GR]^{higher}))),\n         arcs = cbind( c(1, 3),\n                       c(2, 2)),\n         add_functions = 0, \n         contraction = .3\n  )\n```\n\n\n* How could we test the claim that Free Press _caused_ Govt Replaced?\n\n$\\rightarrow$ How can we learn about $U_GR$? \n\n<!-- ## It's all about $U$ -->\n\n<!-- ```{r, echo = FALSE, fig.width = 3, fig.height = 3} -->\n\n<!--   hj_dag(x = c(1, 2, 2), -->\n<!--          y = c(1, 1, 2), -->\n<!--          names = c(\"Rebellion\", \"Crackdown\", expression(paste(U[_]\"), -->\n<!--          c( -->\n<!--          expression(paste(X)), -->\n<!--          expression(paste(u[X])),   -->\n<!--          expression(paste(\"Y\")),   -->\n<!--          expression(paste(u[Y]^{high}))), -->\n\n<!--          arcs = cbind( c(1, 3), -->\n<!--                        c(2, 2)), -->\n<!--          add_functions = 0,  -->\n<!--          contraction = .3, -->\n<!--   ) -->\n<!-- ``` -->\n\n<!-- * To ask whether $X$ caused $Y$ is to ask a question about $U_{Cr}$  -->\n\n<!--     + $X$ did not cause $Y$ iff $U_{Cr}$ caused $Y$ -->\n\n<!-- * Causal inference is then inference about $u$ -->\n\n<!-- * How can we learn about $U$? -->\n\n<!-- * Turn to theory: elaborate and analyze the causal graph -->\n\n\n\n<!-- ## The flow of information: d-separation and d-connectedness (1) -->\n\n<!-- * But first we need some graph-analytic tools -->\n\n<!-- * d-separation and d-connectedness (Pearl 2000) characterize the flow of information between nodes in a causal graph -->\n\n<!--     + What does knowing the value/distribution of one variable in a graph tell you about another? -->\n\n<!-- * $A$ and $B$ are d-connected if there is an unblocked path between them -->\n\n<!--     + A path is any consecutive sequence of edges, regardless of direction, not traversing a pair of head-to-head arrows -->\n\n<!--     + $A\\rightarrow Z\\rightarrow B$: $A$ and $B$ are d-connected -->\n\n<!--     + $A\\leftarrow Z\\rightarrow B$: $A$ and $B$ are d-connected -->\n\n<!--     + _Knowing the value of $A$ conveys information about the value of $B$ and vice versa_ -->\n\n\n<!-- ## The flow of information: d-separation and d-connectedness (2) -->\n\n<!-- * A path between $A$ and $B$ is d-separated if there is no path connecting $A$ and $B$ -->\n\n<!--     + $A\\rightarrow Z\\leftarrow B$: $A$ and $B$ are d-separated (blocked by meeting arrow-heads) -->\n\n<!--     +  _Knowing the value of $A$ conveys NO information about the value of $B$ and vice versa_ -->\n\n<!-- * $A$ and $B$ are d-separated __by $Z$__ if $Z$ blocks a path from $A$ to $B$... -->\n\n<!--     + $A\\rightarrow Z\\rightarrow B$ or  -->\n\n<!--     + $A\\leftarrow Z\\rightarrow B$ -->\n\n<!--     + _Once we know the value of $Z$, finding out $A$ conveys NO information about the value of $B$ (and vice versa)_ -->\n\n\n<!-- ## The flow of information: colliders -->\n\n<!-- * ...as long as $Z$ does not lie at the convergence of two arrows from $A$ and from $B$ -->\n\n<!--     + $A\\rightarrow Z\\leftarrow B$: $Z$ _d-connects_ $A$ and $B$ -->\n\n<!--     + $Z$ is a \"collider\" -->\n\n<!--     + Knowing $A$ alone conveys no information about $B$ -->\n\n<!--     + But _if_ we know $Z$, _then_ knowing $A$ is informative about $B$ -->\n\n\n<!-- ## The flow of information: intuition for colliders -->\n\n<!-- * Suppose admission to a college is a joint function of an applicant's grades and her extracurricular activities -->\n\n<!--     + $G\\rightarrow A\\leftarrow E$ -->\n\n<!-- * If I tell you that an applicant's grades were low, that conveys no information about her extracurricular activities -->\n\n<!--     + $G$ and $E$ are unconditionally d-separated -->\n\n<!-- * But if I tell you that an applicant's grades were low _and_ that she was admitted, you now should update your beliefs about her extracurricular activities $\\rightarrow$ probably high -->\n\n<!--     + $G$ and $E$ are d-connected conditional on the collider, $Z$ -->\n\n<!-- * N.B.: One reason why conditioning on post-treatment variables is risky: it can introduce correlations among variables that are _unconditionally_ independent. -->\n\n\n##Information in $X$\n\nWe already learn about the cause of $Y$ from the value of $X$\n\n```{r, echo = FALSE, fig.width = 3, fig.height = 3}\n\n  hj_dag(x = c(1, 2, 2),\n         y = c(1, 1, 2),\n         names = c(\"Free Press\", \"Govt Replaced\", expression(paste(U[GR]^{higher}))),\n         arcs = cbind( c(1, 3),\n                       c(2, 2)),\n         add_functions = 0, \n         contraction = .3\n  )\n```\n\n* $U_{GR} \\in {t_{00}, t_{01}, t_{11}, t_{10}}$\n\n* $FP$, conditional on $GR$, already contains some information about $U_GR$\n\n* Observing $FP$=$GR$=1 rules out $t_{00}$ and t_{10}$ as values of $U_GR$\n\n$\\rightarrow$ Is it t_{00} or t_{11}?\n\n## Go to a lower-Level DAG: Mediation (1)\n\n* Ask _why_ Free Press might lead to Govt Replacement\n\n* Some theory: Free press leads to reports on official corruption, which leads to government replacement\n\n$\\rightarrow$ a lower-level DAG.\n\nBracketing for now some of the complexity in our original lower-level DAG, we can have:\n\n```{r, echo = FALSE, fig.width = 3, fig.height = 3}\n\n  hj_dag(x = c(1, 2, 2, 3, 3),\n         y = c(1, 1, 2, 1, 2),\n         names = c(\"FP\", \"Media Reports\", expression(paste(U[MR])), \"GR\", expression(paste(U[GR]^{lower}))),\n         arcs = cbind( c(1, 2, 3, 5),\n                       c(2, 4, 2, 4)),\n         add_functions = 0, \n         contraction = .4\n         )\n```\n\n$\\rightarrow$ a research design: Observe $MR$.\n\n## Go to a lower-Level DAG: Mediation (2)\n\n```{r, echo = FALSE, fig.width = 3, fig.height = 3}\n\n  hj_dag(x = c(1, 2, 2, 3, 3),\n         y = c(1, 1, 2, 1, 2),\n         names = c(\"FP\", \"Media Reports\", expression(paste(U[MR])), \"GR\", expression(paste(U[GR]^lower))),\n         arcs = cbind( c(1, 2, 3, 5),\n                       c(2, 4, 2, 4)),\n         add_functions = 0, \n         contraction = .4\n         )\n```\n\n* Now we have separated $U_{GR}^{higher}$ into 2 components\n    \n    + $U_{GR}^{higher}$: exogenous features of our dependent variable that condition its response to the mediator\n    \n        + $U_{GR}^{higher} \\in {t_{00}^{GR}, t_{01}^{GR}, t_{11}^{GR}, t_{10}^{GR}}$\n    \n    + $U_{MR}$: exogenous features of our mediator that condition its response to $X$\n    \n        + $U_{MR} \\in {t_{00}^{MR}, t_{01}^{MR}, t_{11}^{MR}, t_{10}^{MR}}$\n    \n$\\rightarrow$ 16 lower-level causal types\n\n* A positive causal effect in higher-level graph requires either:\n\n    + $t_{01}^{MR}$ and $t_{01}^{GR}$ (two linked positive effects), or\n    \n    + $t_{10}^{MR}$ and $t_{10}^{GR}$ (two linked negative effects)\n\n## Go to a lower-Level DAG: Mediation (3)\n\n* Observing $MR$ yields information about $U_{GR}$ in two ways:\n\n      1. Transmission: Joint observation of $FP$ and $MR$ tells us whether mediator could have conveyed $X$'s effect down the causal chain\n    \n        $\\rightarrow$ narrows possible values of $U_{MR}$ \n        \n      2. Production: Joint observation of $MR$ and $GR$ tells us whether we get the outcome value that the mediator should produce \n    \n        $\\rightarrow$ narrows possible values of $U_{GR}^{higher}$\n        \n    \n\n    \n<!--     2. Expunging $U_{cr}$ of $U_{is}$ (following Markov property of the graph; or could say $Y$ is now d-separated from $U_{cr}$ by $IS$) -->\n\n<!--     + Our inference about $R\\rightarrow Cr$ is now unaffected by unobserved factors acting on $IS$ -->\n\n<!-- * (NB: We ALSO learn from knowing $U_{is}$ -- i.e., we learn about the distribution of causal effects of $R$ on $IS$.) -->\n\n\n## Go to a lower-Level DAG: Mediation (4)\n\nRecall: \n\n* A positive causal effect in higher-level graph requires either:\n\n    + $t_{01}^{MR}$ and $t_{01}^{GR}$, or\n    \n    + $t_{10}^{MR}$ and $t_{10}^{GR}$\n\n* Observing $MR$=0, given $FP=GR=1$, excludes:\n\n    + **$t_{01}^{MR}$**\n    + $t_{11}^{MR}$\n    + $t_{00}^{GR}$\n    + **$t_{01}^{GR}$**\n\n$\\rightarrow$ positive causal effect of $FP$ on $GR$ possible, but must run through linked negative effects (free press **reduces** media reports of corruption, corruption reports reduce chance of govt replacement)\n\n$\\rightarrow$ may be no causal effect\n\n\n\n## Go to a lower-Level DAG: Mediation (5)\n\nRecall: \n\n* A positive causal effect in higher-level graph requires either:\n\n    + $t_{01}^{MR}$ and $t_{01}^{GR}$, or\n    \n    + $t_{10}^{MR}$ and $t_{10}^{GR}$\n\n* Observing $MR$=1, given $FP=GR=1$, excludes:\n\n    + $t_{00}^{MR}$\n    + **$t_{10}^{MR}$**\n    + $t_{00}^{GR}$\n    + **$t_{10}^{GR}$**\n\n$\\rightarrow$ any positive causal effect of $FP$ on $GR$ possible through linked positive effects (free press **increases** media reports of corruption, which increases chance of leaving office)\n\n* We'll return later to discrimination among the possibilities\n\n\n  \n## Go to a lower-level DAG: Other $X$'s (1)\n\nSuppose now we see a case in which there is a Free Press and the Goverment _survives_. \n\nWas there _no_ Govt Replacement because of a Free Press?\n\n* Query theory about _what else_ affects $Y$ besides this $X$?\n\n* Our lower-level DAG tells us that effect $GR$ depends not just on $FP$ but also on incumbent politicians' degree of strategic responsiveness ($S$) to electoral incentives\n\n    + Strategic politicians always seek to enhance their survival prospects\n    \n    + Non-strategic politicians maximize short-run income\n\n```{r, echo = FALSE, fig.width = 3, fig.height = 3}\n\n  hj_dag(x = c(1, 1, 2, 1, 2),\n         y = c(0, 1, 0, 2, 2),\n         names = c(\"FP\", \"S\", \"GR\", expression(paste(U[S])), expression(paste(U[GR]^lower))),\n         arcs = cbind( c(1, 2, 5, 4),\n                       c(3, 3, 3, 2)),\n         add_functions = 0, \n         contraction = .2\n         )\n```\n\n\n## Go to a lower-level DAG: Other $X$'s (2)\n\n```{r, echo = FALSE, fig.width = 3, fig.height = 3}\n\n  hj_dag(x = c(1, 1, 2, 1, 2),\n         y = c(0, 1, 0, 2, 2),\n         names = c(\"FP\", \"S\", \"GR\", expression(paste(U[S])), expression(paste(U[GR]^lower))),\n         arcs = cbind( c(1, 2, 5, 4),\n                       c(3, 3, 3, 2)),\n         add_functions = 0, \n         contraction = .2\n         )\n```\n\n* Again, we have divided $U_GR^higher$ in two:\n\n    + $U_S$: Exogenous determinants of $S$\n    \n    + $U_{GR}^{lower}$: Exogenous features of $GR$ determining its joint responsiveness to $FP$ and $S$\n\n\n## Go to a lower-level DAG: Other $X$'s (3)\n\n* Yields 16 lower-level causal types, defined by possible responses to different combinations of values for $FP$ and $S$\n\n    + We can write these as\n    \n    \\LARGE {$t^{Y|FP=0, S=1; Y|FP=1, S=1}_{Y|FP=0, S=0; Y|FP=1, S=0}$}\n    \n    + \\Large $t^{00}_{00}$, $t^{01}_{00}$, etc.\n\n\n## Go to a lower-level DAG: Other $X$'s (4)\n\nObserving $S$ is informative in 2 ways:\n\n1. Jointly with $FP$ and $GR$, $S$ eliminates causal types\n\n    + Helps us figure out what the effect of $FP$ in this case _would_ be under different states of the world\n    \n    + Observing $S$=1 (with $FP$=1, $GR$=1) eliminates all types in which $Y\\neq 1$ when $FP=GR=1$ ($t^{00}_{00}, t^{00}_{01}, t^{00}_{10}, t^{00}_{11}$)\n    \n2. Observing $S$ also tells us _which state of the world we are in_\n\n    + E.g., _If_ case's type is $t^{01}_{00}$, then $S$=1 tells us that $FP$ had a positive causal effect. \n\n* Still leaves open multiple possibilities for $FP$'s effect on $GR$\n\n    + $FP$ could have caused $GR$ given $S=1$: $t^{01}_{00}$, $t^{01}_{01}$, $t^{01}_{10}$, $t^{01}_{11}$ all consistent with the data\n    \n    + $GR$ could also still have happened _without_ $FP$: $t^{11}_{11}$, $t^{11}_{00}$, $t^{11}_{01}$, $t^{11}_{10}$ also consistent with the data\n\n\n## Strengthen theory\n\n* So far we have used the data to eliminate lower-level causal types, but this hasn't helped us draw a higher-level causal inference.\n\n* Multiple higher-level types (effects of $FP$ on $GR$) consistent with the data\n    \n* But we've been working with a very _thin_ notion of ``theory'': just nodes and edges\n\n* We usually have priors about directions of effects and other features of the relations among nodes\n\n* Inference $f$(priors over types, data)\n\n\n## Mediator clue with stronger theory (1)\n\nFor example:\n\n* Observing $MR$=0, given $FP=GR=1$, excludes:\n\n    + $t_{01}^{MR}$\n    \n    + $t_{11}^{MR}$\n    \n    + $t_{00}^{GR}$\n    \n    + $t_{01}^{GR}$\n    \n    but permits:\n    \n    + $t_{00}^{MR}$\n    \n    + $t_{10}^{MR}$\n    \n    + $t_{11}^{GR}$\n    \n    + $t_{10}^{GR}$ \n\nHowever, are these remaining lower-level types all admissible by our priors?\n\n\n## Mediator clue with stronger theory (2)\n\nPermitted by data: \n\n    1. $t_{00}^{MR}$\n    \n    2. $t_{10}^{MR}$\n    \n    3. $t_{11}^{GR}$\n    \n    4. $t_{10}^{GR}$ \n\n* But are these remaining lower-level types all admissible by our theoretical/background knowledge?\n\n* We would be likely, e.g., to put a low prior probability on: \n\n    + $t_{10}^{MR}$: that having a free press _reduces_ media reports of corruption\n    \n    + $t_{10}^{GR}$: that having media reports about govt corruption _saves_ govts that would otherwise be replaced\n    \n* This leaves two causal types consistent with the data on which we would place a high prior probability: \n\n    + $t_{00}^{MR}$: in which there is no _transmission_ of $FP$ to $MR$\n    \n    + $t_{11}^{GR}$: in which there is no _production_ of $GR$ by $MR$\n\n* Inference: u^{higher} = t_{11}$ = 0 causal effect of $FP$ on \n\n\n## Moderator clue with stronger theory (1)\n\n* Observing $S$=1 (with $FP$=1, $GR$=1) eliminates all types in which $Y\\neq 1$ when $FP=GR=1$ ($t^{00}_{00}, t^{00}_{01}, t^{00}_{10}, t^{00}_{11}$)\n\nPermits\n\n*  $FP=1$ caused $GR=1$: $t^{01}_{00}$, $t^{01}_{01}$, $t^{01}_{10}$, $t^{01}_{11}$\n    \n* $FP=1$ did not cause $GR=1$: $t^{11}_{11}$, $t^{11}_{00}$, $t^{11}_{01}$, $t^{11}_{10}$\n\n* But are all of these types equally consistent with background/theoretical knowledge?\n    \n    <!-- Removes $HR$ from $U_{cr}$, unpacking an unobservable into an observable colliding with a (reduced-variance) unobservable: now $HR$ and $R$, given $Cr$, both provide information on $U_{cr}$ -->\n\n    <!-- + Given structural equations for $Cr$, may tell us whether $X$ can cause $Y$.  -->\n\n    \n    \n    \n## Implications for probative value\n\n```{r, echo = FALSE, fig.width = 3, fig.height = 3}\n\n  hj_dag(x = c(1, 2, 2, 3, 3),\n         y = c(1, 1, 2, 1, 2),\n         names = c(\"X\", \"M\", \"U_M\", \"Y\", \"U_Y\"),\n         arcs = cbind( c(1, 2, 3, 5),\n                       c(2, 4, 2, 4)),\n         add_functions = 0, \n         contraction = .4\n         )\n```\n\n* Key implication: nothing is learned from observing mediators that are _with certainty_ caused by $X$\n\n* The information about $U_Y$ comes from resolving _uncertainty_ about $M$'s value\n\n* The most common process tracing strategy is informative _not_ when our mechanisms are strongly determined by $X$ but when they are only partially so\n\n* QUESTION: A theorem here about some inverted u-shaped relationship between the variance in $M$ attributable to $U_M$ and the probative value of observing $M$??",
    "created" : 1484750426873.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2929052013",
    "id" : "7AA9356C",
    "lastKnownWriteTime" : 1479393510,
    "last_content_update" : 1479393510,
    "path" : "~/Dropbox/ProcessTracing/8 Book/Chapters/2 Causes and Theories/working docs/Alan's working pres file.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}