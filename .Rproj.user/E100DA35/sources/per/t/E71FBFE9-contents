# Design: Clue Selection as a Decision Problem

```{r, include = FALSE}
library(knitr)
```

**\color{blue} Key Ideas: We draw out the implications of the structural model approach for clue selection strategies. We introduce a tool for generating an optimal decision tree for clue selection given, with illustrations on discrete and continuous data.**

Consider now the problem of determining what qualitative data to gather on a case. Evidently it makes sense to gather information on clues that have large probative value, but whether or not clues have probative value can depend on what clues have already been collected: Finding out that the Butler had no motive may be informative for the claim that he is innocent, but it may not be useful if you already know he had no opportunity. 

In our running example, we can see many situations where researchers have a choice of observations that could be informative, and situations in which the informativeness of an observation can depend on what is already known. In Figure \ref{fig:running}, we showed  how one can use the structural equations to provide a set of conditional causal graphs that let one see easily what caused what at different values of the root nodes $S$ and $X$. Each of these plots graphs a particular context. We can thus readily see which collection of root nodes constitutes a given query, or estimand.  Turning things around, we can see, given a query, which nodes are informative of the probability that the query is true.^[With larger graphs, continuous variables, and more stochastic components, it may not be feasible to graph every possible context; but the strategy for inference remains the same.]  

For example, suppose one can see that $X=0$ and  $Y=0$ but does not know the causal effect of $X$ on $Y$  This is equivalent to saying that we know that we are in either panel $A$ or $B$ but we do not know which one. Defining the query in terms of root nodes, the question becomes  $S \stackrel{?}{=} 1$, or $P(S=1|X=0,Y=0)$; the difference between the contexts in the two panels is that $S=0$ when, and only when, $X=0$ causes $Y=0$ . Given the structural equation for $S$, $P(S|X=0,Y=0) = P(S|X=0)$, and given independence of $X$ and $S$, $P(S=1|X=0)= \pi^S$.  Figuring out $S$ fully answers the query: that is, given what we know already, $S$ is doubly decisive for the proposition.^[Graphically what is important is that $S$ is informative not because it is $d-$connected with $Y$, but because it is $d-$connected to the query variable---here, simply, to itself.]

We can also see instances in this example of  how existing data can make clues uninformative. Say one wanted to know if $X$ causes $C$ in a case. As we can see from inspection of the panels, this query is equivalent to asking whether $S=1$ (as $X$ causes $C$ only in those two panels ($B$ and $D$) where $S=1$. Data on $R$ is unconditionally informative about this query as $R$ is not $d-$separated from $S$. For example, $R=1$ implies $S=0$. However, if $C$ and $X$ are already known, then $R$ is no longer informative because $C$ and $X$ together *d*-separate $R$ from $S$.^[We can come to the same conclusion by reasoning with the graphs: if $X=0$ and $C=1$, we know we are in subfigure $A$ or $B$, and $X$ causes $C$ only in panel $B$. However, $R$ is of no help to us in distinguishing between the two contexts as it takes the same value in both graphs.]

The running example also lets us demonstrate how informative clues can be found in many different places in a graph. 

1. **Informative spouses** Spouses---parents of the same child---can inform on one another. As we have seen in other examples, when an outcome has multiple causes, knowing the value of one of those causes helps assess the effect(s) of the other(s). For example, here, $S$ and $X$ are both parents of $C$; $S$ is thus informative for assessing whether $X$ causes $C$. Indeed this query, written in terms of roots, is simply $P(S)$:  $X$ causes $C$ if and only if $S=1$. Likewise, $S$ causes $C$ (negatively) if and only if $X=1$. 

2. **Pre-treatment clues.** Did the absence of media reports on corruption ($R=0$) cause government survival ($Y=0$)? Look to the pre-treatment clue, $X$: $X=0$ is a smoking gun establishing that the absence of a report produced government survival. Or, substantively, if there were a free press, then a missing report would never be a cause of survival since it would occur only in the absence of corruption, which would itself be sufficient for survival. More broadly, this example illustrates how knowledge of selection into treatment can be informative about treatment effects. 

3. **Post-outcome clues.** Suppose we observe the presence of a free press ($X=1$) and want to know if it caused a lack of corruption ($C=0$), but cannot observe the level of corruption directly. Observing $Y$---which occurs after the outcome---is informative here: if $X=1$, then $X$ causes $C$ (negatively) if and only if $Y=0$. When an outcome is not observed, a consequence of that outcome can be informative about its value and, thus, about the effect of an observed suspected cause. 

4. **Mediators as clues**: We see a politically sensitive government ($S=1$) and its survival ($S=0$). Did the government survive because of its sensitivity to public opinion? Here, the mediation clue $C$ is helpful: a lack of corruption, $C=0$, is evidence of $S$'s negative effect on $Y$. -->

And of course, different clues can be  informative in different ways for different types of estimand.

Needed then is a systematic way for identifying what clues to look for, and perhaps, in what order to look for them.

## A strategic approach

The representation of inference problems as one of querying a Bayesian model points to a relatively simple method for answering this question, at least for small problems. Consider first a situation where one has access to data $W$ and wants to know the expected probative value of all possible collections of data one could gather. 

This can be done as follows:

1. First define a model, including a signature $S = (\mathcal{U}, \mathcal{V}, \mathcal{R})$, structural equations $\mathcal{F}$, and beliefs on $\mathcal{U}$, $P()$. 
2. Second, define a query on the model, as a statement about values of $\mathcal{V}$ given different $\mathbb{do}$ operations. 
3. Third, use $P$ to draw a vector of $U$ values and assess whether the query is true or not given $U$ and whether $W$ obtains. Then, over many repeated draws from $P$ calculate the *share* of times that the query  is true  among those cases in which  $W$ is  true. This gives posterior probability on $Q$, $P(Q|W)$.
4. Fourth, given posterior $P(Q|W)$ calculate the probability of observing any realization of values $K'$ given the set of clues sought. For each possible realization calculate posterior variance using $P(Q|W, K')$, itself calculated as the share of draws in which the query is true given both $W$ and the particular set of findings $K'$ obtains.  Calculate the *expected* posterior variance by taking an average of these variances with weights given by the probability of observing the clue pattern in question.
5. Repeat step 4 for all possible collections of clues that one could search for. 

This procedure then returns expected posterior variance associated with a planned search for a collection of clues. A more sophisticated strategy would determine which clues to search for later given findings from clues that are sought first. This reflects the possibility that a given clues $K_2$ may be informative if another clue $K_1$ turns up positive but not if it comes out negative. 

We provide some tools for both of these  approaches and illustrate them below.

## Clue selection for the running example

Lets return to the running example and assess the informativeness of different clue strategies. 

Recall that a model consists of an ordered set of variables $V$, a set of exogenous variables $U$, with a distribution over these, given by $P(u)$ and a set of functions, one for each $V\in\mathcal{V}$, $f_v(v',u_v)$ which takes as arguments a subset of variables in $\mathcal{V}$ that must be prior to $V$ in the ordering plus an element of $U$ associated with $V$.  

**Step 1.** We will define a model as a list, technically a triple using the function `biqq_model`. Here is a version of the model in our running example. This differs from the original by having units comply with the specified functions with probability .8 and otherwise take on 0 or 1 with equal probabilities. Thus any data combination is possible. 

```{r model6a, echo = TRUE, warning = FALSE, message = FALSE}
# Define a model
library(biqq)
model <- biqq_model(
    var_names = c("S", "X", "C", "R","Y"),
    var_functions = list( 
          f_S = function(U,V) U[1] < .5,
          f_X = function(U,V) U[2] < .5,
          f_C = function(U,V) (1- (V[1]*V[2]))*(U[3]>.2) +(U[3]<.1),
          f_R = function(U,V) V[2]*V[3]*(U[4]>.2) + (U[4]<.1),
          f_Y = function(U,V) V[3]*V[4]*(U[5]>.2)+ (U[5]<.1)),
  P =  function() runif(5)
  )
```


The main thing to note here is that that variable ordering is critical. All descendants follow ancestors. All functions in $\mathcal{F}$ (`var_functions`)  take $U$ and $V$ as arguments

With a model in hand we have all we need to start generating realizations of the world. This can be doe using a function `biqq_world`  that propagates a realization of $U$ through the model. The function allows for the possibility that some variable values are "controlled", using a `do` operator. 

```{r world, include = FALSE}
biqq_world(model)
```

**Step 2: A query.** To define a query we will define two functions,  `operation`, which applies some `do` operators to a world, and a `query` which asks a question about the values of variables in that world after these do operators are implemented.  For example we might consider two operations `do(X)=0` and  `do(X)=1` and the query is whether these operations are associated with $Y=0$ (the fifth variable here) under the first operation and $Y=1$ in the second operation.

```{r}
my_operations <- list(c(0, NA, NA, NA, NA), c(1, NA, NA, NA, NA))
my_query      <- function(x) (x[[1]][5] ==1) & (x[[2]][5] == 0)
```
  
**Step 3. Posterior probabilities.** A function `biqq_which` then assesses whether the query is satisfied or not for different worlds. The function operates  by simulation and is essentially a grid search. Given a model and a query it generates a large collection of worlds and assesses in each one whether the query is satisfied or not. 

```{r example}
example <- biqq_which( model,
                       operations = my_operations,
                       query = my_query )
```

The output of the `biqq_which` function is a list that contains a matrix of contexts, $U$, the outcomes associated with them $V$, and an indicator for whether the query is satisfied or not in each context. The function can also give a graphical representation of the contexts in which the query is satisfied, as shown in Figure \ref{biqqwhich}.

```{r example2, echo = FALSE, fig.cap = "\\label{biqqwhich} Illustration of worlds for which the query is true (black points) or false (pink points)."}
example <- biqq_which( model,
                       operations = my_operations,
                       query = my_query,
                       plotit = TRUE
                       )
```

Once a distribution of worlds is generated like this---along side information on whether the query is answer in each---it is easy to extract all kinds of quantities. For example the average effect of changing $S;$ from 0 to 1 is simply the mean of the distribution of the query variable: `r mean(example$A)` ; the average effect of changing S from 0 to 1, given $Y=0$  and $S=1$ is the mean of the query conditional on these values of $Y$ and $S$: `r round(mean(example$A[example$V$Y==0 &  example$V$S==1]),2)`. Indeed, this is enough to calculate the probative value of any variable in any state. If the expected value of the query is different for two possible values of some variable, then that variable has probative value for the query.  


**4 Calculate probative value and expected reducton in variance.** 

We can now assess the reduced variance from any clue strategy, $K$,  given existing data, $W$. Here we assume that we have observed a positive outcome on the fourth variable ($R$), but no other data, and consider the gains from three other strategies.

```{r perm, include = FALSE}
perm <- function(v) {
  sapply(1:length(v), function(x) {
    rep( rep(1:v[x], each=prod(v[x:length(v)]) / v[x]),
         length.out=prod(v))
  } ) - 1
}

pKw(model=model, my_operations, my_query, sims=200, W = rep(NA,5), K=c(TRUE, FALSE, FALSE, FALSE, FALSE))
```


```{r learning_functions}
expected_variance <-
    biqq_learning(model, 
                  my_operations, 
                  my_query,  
                  W  = c(NA, NA, NA, 1, NA),
                  Ks = rbind(
                    c(TRUE,  FALSE, FALSE, FALSE, FALSE),
                    c(FALSE, FALSE,  FALSE, FALSE, TRUE),
                    c(TRUE,  TRUE,  FALSE,  FALSE,  TRUE))
                    )
```

The output  is shown in Table \ref{ev}.

```{r, echo = FALSE}
ev <- matrix(round(expected_variance,3),nrow =1)
colnames(ev) <- names(expected_variance)
kable(ev, caption = "\\label{ev} Expected variance given a set of specified strategies")
```

In the same way we  can figure out outcomes for all possible profiles of data one might have on $m$ binary variables. With five variables there are 243 ($3^5$) combinations of 0s, 1s and unknowns.  We provide a function which allows specific examines or else examinations of the form "all strategies that seek up to $m_k$ clues when up to $m_w$ variables are already observed."


```{r}
my_strategies <- biqq_strategies(
  model, 
  operations = my_operations, 
  query = my_query, 
  m_K=2, 
  m_W=2)
```

This produces a matrix shown here as table \ref{kstrategies} for a situation in which all two clue strategies are examined given two previous observations.


```{r showstrats5, echo = FALSE}
# colnames(my_strategies)[1:2] <- c("Prior var", "Var given W")

kable(my_strategies[1:20, 1:12], caption="\\label{kstrategies} A fragment of the table of expected posterior variance for all two clue strategies given observations on two nodes. Firs column gives prior variance, second gives variance condition on data pattern $W$, as indicated by row labels; subsequent columns give expected variance when different clues are sought. ")
```

### Dynamic Strategies

The clue collection strategies described above assume that researchers identify the full set of clue to be gathered in advance and do not alter their in Given $n$ nodes, a data collection strategy will be of the form:
$$\sigma = \{K_1, (K_2|K_1 = 1), (K_2|K_1 = 0), (K_3|K_1=1, K_2 =0)\dots\}$$

where each $K_j$ is en element of the nodes on the graph, or is the empty set. Each of these strategies has an associated expected reduction in variance as well as an associated expected cost. Such a strategy vector specifies the first clue, and then subsequent clues condition on what was found from previous searches. We restrict strategies to those in which each clue is sought at most once (though possibly sought at times that depends on findings), and in which if a clue is sought it is sought immediately. For a risk neutral decision maker, this may be sufficient to choose among them. 

In the running example with five binary nodes the strategies needs to specify up to $2^4$ decision points, reflecting the initial choice and the decisions made after learning about four nodes. An example of a strategy, summarizing contingent plans is the below:




```{r, include = FALSE}
random_list_strategy <- function(n){
  out <- list()
  for(j in 1:n){
  out[[j]] <- sample(1:n, 2^{j-1}, replace = TRUE)
  }
  out
  }
random_list_strategy(4)


# Records which cases are sought given a list of choice instructions and a realization, r
sought <- function(strategy, r){
  r <- unlist(r)
  n <- length(strategy)
  z <- rep(NA, n)
  z[1] <- strategy[[1]]
  for(j in 2:n){
    z[j] <- strategy[[j]][1 + sum( sapply(1:(j-1), function(i) r[z[i]]*2^(j-i-1)))]
    }
  z}

k = 2
strategy <- random_list_strategy(k)
r = sample(0:1, k, replace = TRUE)
print("Strategy"); strategy
print("World"); r
print("Sought"); sought(strategy,r)
```



```{r, include = FALSE}
strategy_cost_benefit <- function(
  model, 
  operations, 
  query, 
  sims=100, 
  U=NULL, 
  n    =  nrow(U),
  cost = rep(1,n),
  strategy = NULL,  # Or a matrix with one column per node indicating whther to be sought or not
  asraw = FALSE # PRovide raw matrix of clues sought and variance; otherwise only summary provided
  ){

  if(is.null(U)) U <- (replicate(sims, model$P()))
  sims <- ncol(U)
  n    <- nrow(U)
  if(n != length(strategy)) stop ("strategy should have n components")
  result <- biqq_which(
                         model,
                         operations = operations,
                         query = query,
                         U=U,
                         plotit = FALSE)
  V  <- t(as.matrix(result$V))
  Ks0 <- sapply(1:sims, function(j) sought(strategy, V[,j]))
  Kf <- function(v) 1:n %in% v
  Ks <- as.matrix((apply(Ks0, 2, Kf)))   # TRUE if v[i] is sought
  K  <- matrix(NA, n, sims)
  K[Ks] <- V[Ks]
  En <- mean(apply(Ks, 2, sum))  # Expected number of clues sought
  Ec <- mean(t(Ks)%*%matrix(cost, 5, 1))  # Expected cost of clues sought

  # Posterior variance that will be achieved in each state of the world
  pV <- sapply(1:sims, function(j) {
      inK <- sapply(1:sims, function(i) !(0 %in% (1*(V[,i] == K[,j]))))
      var(result$A[inK])})
  # Note need to think about this step: the  posterior is calculated for each set of observations counting as possible all worlds that have these observations no matter how different they look on other fronts. This is because all data used to select the observed data is in the observed data. eg say two worlds  have  V1=1 and differ on everything else. Say that W contains V1=1 and no other data. Then the posterior relative likelihood of these two worlds is the same as the prior relative likelihoods. Note also that sims have to be large to avoid bias in estimate of variance.   
  
  
out <- c("Expected posterior variance"=mean(pV, na.rm = TRUE), "Expected number of clues sought"=En, "Expected Cost"=Ec)
if(asraw) out <- cbind(t(Ks0), pV)
return(out)  
}

```


```{r Strat_Ill, include = FALSE}
prices <- .5+.5*runif(5)

strategy <- random_list_strategy(5)

strategy_cost_benefit(  model,  my_operations, my_query, sims=100,   U=NULL,   cost = prices,   strategy = strategy  # Or a matrix with one column per node indicating whether to be sought or not
  )

```


Note that strategies cannot use information unavailable ex ante. To ensure the right structure we specify the strategy as $n$ vectors, of length $1, 2, 4, \dots$. For example of the form $\{\{1\}, \{2,3\}, \{3, 4, \emptyset, \emptyset\}\}$

This has the interpretation: seek evidence on node 1 first, if one finds $V_1=1$ seek evidence on node 2, otherwise seek evidence on node 3, if $V_1=1$ and $V_2=1$ seek evidence on node 3, but if $V_1=1$ and $V_2=0$ seek $V_4$, if $V_3$ is positive stop seeking.

For each strategy we can then assess the expected variance reduction; in addition, if collecting different clues comes at different costs---but collection depends on past findings---then we can also calculated the expected costs of each strategy.

```{r, include = FALSE, cache = TRUE}
U <- replicate(1000, model$P())
strats <- list()
out <- list()

k <- 100
for(i in 1:k){
  print(i)
  strategy <- random_list_strategy(5)
  strats[[i]] <- strategy
  out[[i]] <- strategy_cost_benefit(  model,  my_operations, my_query, U=U,   cost = prices,
    strategy = strategy  # Or a matrix with one column per node indicating whther to be sought or not
    )
  }

v <- unlist(sapply(1:length(out), function(i) out[[i]][1]))
n <- unlist(sapply(1:length(out), function(i) out[[i]][2]))
c <- unlist(sapply(1:length(out), function(i) out[[i]][3]))
best <- (1:k)[(v+n) == min(v+n)]
lowestvar <- (1:k)[(v) == min(v)]

find_optimals <- function(r=2000){
  best_s <- function(s) (1:k)[(v+s*n) == min(v+s*n)]
  unique(sapply(c(1/(r:1), 1:r), best_s))}
optimals <- find_optimals()

plot(v,n, xlab = "Expected Posterior Variance from Strategy", ylab =  "Expected Number of Clues Sought", col = "orange", pch = 19)
points(v[optimals], n[optimals], pch = 21, cex = 1.2, col = "red")
#print(strats[[best]])
#print(strats[[lowestvar]])

k <- floor((length(optimals)+1)/2)
median_strat = optimals[k]  # Not great for even number
print(strats[[median_strat]])
```

Figure \ref{somesstrats} below plots a collection of strategies based on two criteria---the variance reduction and the expected number of clues sought, which could be an indicator for cost. One can see a frontier of optimal strategies, depending on how these two desiderata trade-off against each other.

```{r, echo = FALSE, fig.cap = "\\label{somesstrats} Non dominated strategies are circled."}
plot(v,n, xlab = "Expected Posterior Variance from Strategy", ylab =  "Expected Number of Clues Sought.", col = "grey", pch = 19)
points(v[optimals], n[optimals], pch = 21, cex = 1.2, col = "black")
```


```{r graph_strategy, include = FALSE}

g_strat <- function(strategy){
  n = length(strategy)
  plot(1:n, type = "n", xlim = c(0,n), ylim = c(-2^(n-2)+.5, 2^(n-2))-.5, axes = FALSE, xlab = "", ylab = "", main = "Decision Tree")
  for(j in 1:length(strategy)){
    sj <- strategy[[j]]
    x <- rep(j, length(sj)) -1
    y <- ((0:(length(sj)-1) - (length(sj)-1)/2))
    if(max(y)>0) y <- y*(j/max(y))
    points(x, y)
    text(x+.25, y, sj, col = "red")
  }
    for(j in 1:(length(strategy)-1)){
    sj  <- strategy[[j]]
    sj2  <- strategy[[j+1]]
    x <- rep(j, length(sj)) -1
    y <- ((0:(length(sj)-1) - (length(sj)-1)/2))
    if(max(y)>0)  y <- y*(j/max(y))
    y1 <- rep(y, each = 2)
    y2 <- ((0:(length(sj2)-1) - (length(sj2)-1)/2))
    if(max(y2)>0)y2 <- y2*((j+1)/max(y2))
    segments(x,y,x+.5, y)
    segments(x+.5,y1,rep(x+1, each = 2), y2)
    text(x+.75, .5*(y1+y2)[rep(c(TRUE, FALSE), length(y2)/2)] - .2, 0, cex = .8)
    text(x+.75, .5*(y1+y2)[rep(c(FALSE, TRUE), length(y2)/2)]+.2, 1, cex = .8)
    }
}
```

Below we graph one of these strategies on the frontier (the median strategy on the frontier) as a decision tree. The interpretation is to seek the first clue first; it will be revealed to be present (1) or not(0), a subsequent branch is then chosen depending on what is found and the indicated clue then sought, and so on. (Note currently the strategy sets we examine include ones in which the same clue is sought multiple times)

```{r, echo = FALSE, fig.height = 8, fig.width = 6, fig.cap = "\\label{dtree} A clue seeking strategy, indicating what to seek first; then what to seek second conditional on first findings, and so on."}
g_strat(strats[[median_strat]])
```  
  
## More complex problems

Illustration of clue inference for a continuous problem.

## Conclusion

Explicit statement of a causal model---including prior beliefs over roots---allows one to assess what will be inferred from all possible observations. This opens the way for simple strategies for assessing what data is most valuable, and in what order it should be gathered. 

We are conscious that here we are pushing the basic logic to the limits. In practice researchers will often find it difficult to describe a model in advance and to place beliefs on nodes. Moreover the collection of new data could easily give rise to possibilities and logics that were not previously contemplated. Nothing here seeks to deny these facts; the claim here is a simpler one: insofar as one can specify a model before engaging in data gathering, the model provides a powerful tool to assess what data is most useful to gather. 



